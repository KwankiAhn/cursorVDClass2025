#include "LogFileWatcher.hpp"
#include <iostream>
#include <fstream>
#include <filesystem>
#include <thread>
#include <chrono>
#include <nlohmann/json.hpp>

// static ë©¤ë²„ ë³€ìˆ˜ ì •ì˜
const size_t LogFileWatcher::MAX_BUFFER_SIZE;
const int LogFileWatcher::WATCH_INTERVAL_MS;

LogFileWatcher::LogFileWatcher(const std::string& logFilePath)
    : logFilePath_(logFilePath)
    , lastPosition_(0)
    , parser_(std::make_unique<LogParser>())
    , stats_(std::make_unique<LogStats>())
{
    // íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if (!std::filesystem::exists(logFilePath_))
    {
        throw std::runtime_error("ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: " + logFilePath_);
    }
    
    // ì´ˆê¸° íŒŒì¼ í¬ê¸° í™•ì¸
    std::ifstream file(logFilePath_, std::ios::ate);
    if (file.is_open())
    {
        lastPosition_ = file.tellg();
        file.close();
    }
    
    std::cout << "ğŸ“ ë¡œê·¸ íŒŒì¼ ê°ì‹œ ì¤€ë¹„ ì™„ë£Œ: " << logFilePath_ << std::endl;
}

LogFileWatcher::~LogFileWatcher()
{
    stopWatching();
}

void LogFileWatcher::startWatching(const std::string& keyword)
{
    if (isWatching_.load())
    {
        std::cout << "âš ï¸  ì´ë¯¸ ê°ì‹œ ì¤‘ì…ë‹ˆë‹¤." << std::endl;
        return;
    }
    
    keyword_ = keyword;
    shouldStop_.store(false);
    isWatching_.store(true);
    
    std::cout << "ğŸ” ì‹¤ì‹œê°„ ë¡œê·¸ ê°ì‹œ ì‹œì‘..." << std::endl;
    if (!keyword_.empty())
    {
        std::cout << "ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: " << keyword_ << std::endl;
    }
    
    // ê°ì‹œ ìŠ¤ë ˆë“œ ì‹œì‘
    watchThread_ = std::make_unique<std::thread>(&LogFileWatcher::watchLoop, this);
}

void LogFileWatcher::stopWatching()
{
    if (!isWatching_.load())
    {
        return;
    }
    
    std::cout << "ğŸ›‘ ë¡œê·¸ ê°ì‹œ ì¤‘ì§€ ì¤‘..." << std::endl;
    shouldStop_.store(true);
    
    if (watchThread_ && watchThread_->joinable())
    {
        watchThread_->join();
    }
    
    isWatching_.store(false);
    std::cout << "âœ… ë¡œê·¸ ê°ì‹œ ì¤‘ì§€ ì™„ë£Œ" << std::endl;
}

bool LogFileWatcher::isWatching() const
{
    return isWatching_.load();
}

void LogFileWatcher::setJsonOutputEnabled(bool enable)
{
    jsonOutputEnabled_ = enable;
}

void LogFileWatcher::watchLoop()
{
    while (!shouldStop_.load())
    {
        try
        {
            if (checkFileChanges())
            {
                processNewLines();
                
                if (jsonOutputEnabled_)
                {
                    writeStatusJson();
                    writeStatsJson();
                }
            }
        }
        catch (const std::exception& e)
        {
            std::cerr << "âŒ ê°ì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: " << e.what() << std::endl;
        }
        
        // 1ì´ˆ ëŒ€ê¸°
        std::this_thread::sleep_for(std::chrono::milliseconds(WATCH_INTERVAL_MS));
    }
}

bool LogFileWatcher::checkFileChanges()
{
    try
    {
        // íŒŒì¼ í¬ê¸° í™•ì¸
        auto currentSize = std::filesystem::file_size(logFilePath_);
        
        if (currentSize > static_cast<std::uintmax_t>(lastPosition_))
        {
            return true;
        }
        else if (currentSize < static_cast<std::uintmax_t>(lastPosition_))
        {
            // íŒŒì¼ì´ íšŒì „ë˜ì—ˆì„ ê°€ëŠ¥ì„± (ì‘ì•„ì¡Œì„ ë•Œ)
            std::cout << "ğŸ”„ íŒŒì¼ íšŒì „ ê°ì§€ë¨" << std::endl;
            lastPosition_ = 0;
            return true;
        }
    }
    catch (const std::exception& e)
    {
        std::cerr << "âŒ íŒŒì¼ í¬ê¸° í™•ì¸ ì¤‘ ì˜¤ë¥˜: " << e.what() << std::endl;
    }
    
    return false;
}

void LogFileWatcher::processNewLines()
{
    std::ifstream file(logFilePath_);
    if (!file.is_open())
    {
        std::cerr << "âŒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: " << logFilePath_ << std::endl;
        return;
    }
    
    // ë§ˆì§€ë§‰ ì½ì€ ìœ„ì¹˜ë¡œ ì´ë™
    file.seekg(lastPosition_);
    
    std::string line;
    bool hasNewError = false;
    
    while (std::getline(file, line))
    {
        if (line.empty()) continue;
        
        // ë¡œê·¸ íŒŒì‹±
        LogEntry entry = parser_->parseLine(line);
        
        // í†µê³„ ì—…ë°ì´íŠ¸
        if (!keyword_.empty())
        {
            stats_->addEntryWithKeyword(entry, keyword_);
        }
        else
        {
            stats_->addEntry(entry);
        }
        
        // ë²„í¼ì— ì¶”ê°€
        addToBuffer(entry);
        
        // ERROR ë¡œê·¸ ì²˜ë¦¬
        if (entry.level == "ERROR")
        {
            hasNewError = true;
            std::cout << "ğŸš¨ [ERROR ê°ì§€] " << entry.rawLine << std::endl;
        }
        
        // í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
        if (!keyword_.empty() && parser_->containsKeyword(entry.rawLine, keyword_))
        {
            std::cout << "ğŸ” [í‚¤ì›Œë“œ ë°œê²¬] " << entry.rawLine << std::endl;
        }
    }
    
    // í˜„ì¬ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
    lastPosition_ = file.tellg();
    file.close();
    
    if (hasNewError)
    {
        std::cout << "ğŸ”” ìƒˆë¡œìš´ ì—ëŸ¬ ë°œìƒ ì•Œë¦¼!" << std::endl;
    }
}

void LogFileWatcher::writeStatusJson()
{
    using json = nlohmann::json;
    
    const auto& statistics = stats_->getStatistics();
    
    json statusJson;
    statusJson["hasNewError"] = (statistics.errorEntries.size() > 0);
    statusJson["errorCount"] = statistics.levelCounts.at("ERROR");
    statusJson["totalLines"] = statistics.totalLines;
    statusJson["lastUpdate"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()).count();
    
    // í‚¤ì›Œë“œ ê´€ë ¨ ì •ë³´
    if (!keyword_.empty())
    {
        statusJson["keyword"] = keyword_;
        auto keywordIt = statistics.keywordCounts.find(keyword_);
        statusJson["keywordCount"] = (keywordIt != statistics.keywordCounts.end()) ? keywordIt->second : 0;
    }
    
    // status.json íŒŒì¼ ì“°ê¸°
    std::ofstream file("status.json");
    if (file.is_open())
    {
        file << statusJson.dump(2);
        file.close();
    }
    else
    {
        std::cerr << "âŒ status.json íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨" << std::endl;
    }
}

void LogFileWatcher::writeStatsJson()
{
    using json = nlohmann::json;
    
    const auto& statistics = stats_->getStatistics();
    
    json statsJson;
    
    // ê¸°ë³¸ í†µê³„
    statsJson["summary"] = {
        {"totalLines", statistics.totalLines},
        {"lastUpdate", std::chrono::duration_cast<std::chrono::milliseconds>(
            std::chrono::system_clock::now().time_since_epoch()).count()}
    };
    
    // ë¡œê·¸ ë ˆë²¨ë³„ í†µê³„
    statsJson["levelCounts"] = json::object();
    for (const auto& [level, count] : statistics.levelCounts)
    {
        if (count > 0)
        {
            statsJson["levelCounts"][level] = count;
        }
    }
    
    // ìµœê·¼ ë¡œê·¸ ë²„í¼ (ìµœëŒ€ 20ê°œë§Œ)
    {
        std::lock_guard<std::mutex> lock(bufferMutex_);
        statsJson["recentLogs"] = json::array();
        
        size_t startIndex = recentLogBuffer_.size() > 20 ? recentLogBuffer_.size() - 20 : 0;
        for (size_t i = startIndex; i < recentLogBuffer_.size(); ++i)
        {
            const auto& entry = recentLogBuffer_[i];
            statsJson["recentLogs"].push_back({
                {"timestamp", entry.timestamp},
                {"level", entry.level},
                {"message", entry.message},
                {"rawLine", entry.rawLine}
            });
        }
    }
    
    // í‚¤ì›Œë“œ ë§¤ì¹­ ì •ë³´
    if (!keyword_.empty())
    {
        statsJson["keywordMatches"] = json::array();
        for (const auto& entry : statistics.keywordMatches)
        {
            statsJson["keywordMatches"].push_back({
                {"timestamp", entry.timestamp},
                {"level", entry.level},
                {"message", entry.message},
                {"rawLine", entry.rawLine}
            });
        }
    }
    
    // stats.json íŒŒì¼ ì“°ê¸°
    std::ofstream file("stats.json");
    if (file.is_open())
    {
        file << statsJson.dump(2);
        file.close();
    }
    else
    {
        std::cerr << "âŒ stats.json íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨" << std::endl;
    }
}

void LogFileWatcher::addToBuffer(const LogEntry& entry)
{
    std::lock_guard<std::mutex> lock(bufferMutex_);
    
    if (recentLogBuffer_.size() >= MAX_BUFFER_SIZE)
    {
        recentLogBuffer_.pop_front();
    }
    
    recentLogBuffer_.push_back(entry);
} 